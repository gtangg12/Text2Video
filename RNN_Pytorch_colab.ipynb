{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('ml': conda)",
      "language": "python",
      "name": "python388jvsc74a57bd06d55b71dc135b52e82d5f98f8e1794e021dfdf681f9370d588ff2fb4ac316953"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "RNN Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggJ2EXEP4t7Q"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import os\n",
        "class FacePredict(nn.Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize using a pretrained tf model\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(28, 60)\n",
        "        self.dropout = nn.Dropout(p=0.7)\n",
        "        self.dense = nn.Linear(60, 20)\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        hid0, _ = self.lstm(inputs)\n",
        "        hiddrop = self.dropout(hid0)\n",
        "        return self.dense(hid0)\n",
        "    \n",
        "    def load_weights_tf(self):\n",
        "        #get the weights from tf model\n",
        "        with torch.no_grad():\n",
        "            #reorder weights to convert from tf to torch\n",
        "            wii, wic, wif, wio = np.split(weights[2][:28, :], 4, 1)\n",
        "            whi, whc, whf, who = np.split(weights[2][28:, :], 4, 1)\n",
        "            wih = np.concatenate((wii, wif, wic, wio), axis = 1)\n",
        "            whh = np.concatenate((whi, whf, whc, who), axis = 1)\n",
        "\n",
        "            self.lstm.weight_ih_l0.data = torch.from_numpy(wih).transpose(0,1)\n",
        "            self.lstm.weight_hh_l0.data = torch.from_numpy(whh).transpose(0,1)\n",
        "            self.lstm.bias_hh_l0.data = torch.from_numpy(weights[3])\n",
        "            self.lstm.bias_ih_l0.data = torch.zeros((240))\n",
        "\n",
        "            self.dense.weight.data = torch.from_numpy(weights[0].T)\n",
        "            self.dense.bias.data = torch.from_numpy(weights[1])\n"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAN2xhGC4t7S"
      },
      "source": [
        "def get_audio_derivatives(audio):\n",
        "    #calculate audio derivatives, return timestamps too\n",
        "    audiodiff = audio[1:,:-1] - audio[:-1, :-1]\n",
        "    times = audio[:, -1]\n",
        "    return np.concatenate((audio[:-1, :-1], audiodiff[:, :]), axis=1), times\n",
        "\n",
        "def shifted_time(i, times):\n",
        "      if i >= 20:\n",
        "        return times[i - 20]\n",
        "      else:\n",
        "        return times[0]"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tj_1jBQX7xOF",
        "outputId": "c4c55eaa-1874-451e-cf48-92145e4700c9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5GtmM7vkBPL"
      },
      "source": [
        "person = 'trump'\n",
        "dataset_name = {'obama':'nHREBzHqFTQ', 'trump':'xAAmF3H0-ek'}[person]"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpELyNiV4t7Z",
        "outputId": "95c4523d-2ce1-4df3-eb98-2805a18e9f84"
      },
      "source": [
        "audio_preprocessed = np.load(f'/content/drive/MyDrive/6869/{dataset_name}_audio.npy')\n",
        "audio_data = get_audio_derivatives(audio_preprocessed)[0]\n",
        "print(audio_data.shape)\n",
        "audio_mean = audio_data.mean(axis = 0)\n",
        "audio_std = audio_data.std(axis = 0)"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(57190, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK-tgFDI4t7V"
      },
      "source": [
        "class FacePredictFineTune(FacePredict):\n",
        "    def __init__(self, mean, std):\n",
        "        super().__init__()\n",
        "        self.dense_input = nn.Linear(28, 28, bias = False)\n",
        "        self.dense_diff = nn.Linear(60, 20, bias = False)\n",
        "\n",
        "        nn.init.zeros_(self.dense_input.weight)\n",
        "        \n",
        "        nn.init.xavier_uniform_(self.dense_diff.weight)\n",
        "        \n",
        "        self.bn = nn.BatchNorm1d(28) #not used\n",
        "        self.mean = torch.from_numpy(mean).requires_grad_(False)\n",
        "        self.std = torch.from_numpy(std).requires_grad_(False)\n",
        "\n",
        "        \"\"\"\n",
        "        for param in self.lstm.parameters():\n",
        "            param.requires_grad = False\n",
        "        \"\"\"\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        #shape T*B*D (time*batch*num_feat)\n",
        "        inputs_transformed = inputs# + self.dense_input(inputs)/10\n",
        "        inputs_norm = (inputs_transformed - self.mean[None, None, :]) / self.std[None, None, :]\n",
        "        hid0, _ = self.lstm(inputs_norm)\n",
        "        hiddrop = self.dropout(hid0)\n",
        "        return self.dense(hid0) #+ self.dense_diff(hid0)/10\n",
        "\n",
        "    def cuda(self):\n",
        "        super().cuda()\n",
        "        self.mean, self.std = self.mean.cuda(), self.std.cuda()"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpqUXq-c4t7X",
        "outputId": "7103c7a1-aa23-4590-a1da-a96a8839e720"
      },
      "source": [
        "model = FacePredictFineTune(audio_mean, audio_std)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/6869/face predict'))\n",
        "model.double()\n",
        "model.cuda()\n",
        "model.train()\n",
        "#torch.save(fpf.state_dict(), 'face predict')"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FacePredictFineTune(\n",
              "  (lstm): LSTM(28, 60)\n",
              "  (dropout): Dropout(p=0.7, inplace=False)\n",
              "  (dense): Linear(in_features=60, out_features=20, bias=True)\n",
              "  (dense_input): Linear(in_features=28, out_features=28, bias=False)\n",
              "  (dense_diff): Linear(in_features=60, out_features=20, bias=False)\n",
              "  (bn): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LonmBhL98bRL",
        "outputId": "eafda5ac-a0c8-4e83-ed63-3dc9ad25fca8"
      },
      "source": [
        "video_data = np.load(f'/content/drive/MyDrive/6869/{dataset_name}_landmarks_frontalized.npy').reshape(-1, 25, 2)\n",
        "video_lip_fiducials = video_data[:, 5:].reshape(-1, 40)\n",
        "video_lip_fiducials = video_lip_fiducials[:, list(range(24)) + list(range(26,32)) + list(range(34,40))]\n",
        "video_lip_fiducials.shape"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16947, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85tKk-fX8cEG",
        "outputId": "c8b65a8a-b3fa-4378-f051-c3a908a60987"
      },
      "source": [
        "#crop and shift of video, in seconds\n",
        "start_frame = {'obama': 303, 'trump': 12}[person]\n",
        "end_frame = {'obama': 6103, 'trump': 16959}[person]\n",
        "video_start = start_frame*100//30 #12\n",
        "video_end = (end_frame - 1)*100//30 #inclusive 16958\n",
        "video_shft = 20\n",
        "video_start"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9hFpph8_UqY"
      },
      "source": [
        "#preprocess video using pca\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components = 20)\n",
        "lip_features = pca.fit_transform(video_lip_fiducials)\n",
        "\n",
        "#constructing differentiable inverse to pca\n",
        "pca_mean = torch.from_numpy(pca.inverse_transform(np.zeros((1, 20)))).cuda().requires_grad_(False)\n",
        "pca_inverse_mat = torch.from_numpy(pca.inverse_transform(np.eye(20))).cuda().requires_grad_(False) - pca_mean\n",
        "\n",
        "def pca_inverse(coeffs): #pca inverse function\n",
        "    return torch.matmul(coeffs, pca_inverse_mat) + pca_mean\n",
        "\n",
        "#upsampling\n",
        "from scipy.interpolate import interp1d\n",
        "video_times = np.arange(start_frame, end_frame)/30\n",
        "lips_interpolate = interp1d(video_times, lip_features, axis = 0)\n",
        "audio_times = np.arange(video_start, video_end)/100\n",
        "lips_upsampled = lips_interpolate(audio_times)"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZUVh2XO4t7Y"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "class FacePredictDataset(Dataset):\n",
        "    def __init__(self, inputs, outputs, predict_delay, output_begin, num_cuts = 18):\n",
        "        #temporally inputs[output_begin] matches with outputs[0]\n",
        "        #in rnn match inputs[output_begin + predict_delay] with outputs[0] \n",
        "\n",
        "        #crop outputs\n",
        "        output_length = len(outputs)\n",
        "        crop_len = output_length // num_cuts\n",
        "        self.outputs = [outputs[crop_len*n:crop_len*(n+1)] for n in range(num_cuts)]\n",
        "\n",
        "        #find matching parts of inputs\n",
        "        self.inputs = [inputs[crop_len*n + output_begin: crop_len*(n+1) + output_begin + predict_delay] for n in range(num_cuts)]\n",
        "        self.len = num_cuts\n",
        "        self.crop_len = crop_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return [self.inputs[idx], self.outputs[idx], self.crop_len * idx]"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF5ftbo9HXIJ"
      },
      "source": [
        "#create datasets\n",
        "idx_split = 45000\n",
        "train_crops = 1400\n",
        "train_data = FacePredictDataset(audio_data, lips_upsampled[:idx_split], video_shft, video_start, train_crops)\n",
        "\n",
        "test_crops = 300\n",
        "test_data = FacePredictDataset(audio_data[idx_split:], lips_upsampled[idx_split:], video_shft, video_start, test_crops)\n",
        "\n",
        "test_dataloader = DataLoader(test_data, batch_size=300, shuffle=True)\n",
        "train_dataloader = DataLoader(train_data, batch_size=100, shuffle=True)"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImCq81_KJcHh"
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "#define our loss functions\n",
        "inner_lip_pairs = ((13, 19), (14, 18), (15, 17))\n",
        "def inner_lip_distance(coeffs):\n",
        "    landmarks = pca_inverse(coeffs)\n",
        "    return sum([torch.square(landmarks[:, :, u] - landmarks[:, :, l]) for u, l in inner_lip_pairs])\n",
        "\n",
        "def volume(audio_features):\n",
        "    return audio_feature[13]\n",
        "\n",
        "def hyperbolic_loss(y1, y2):\n",
        "    return torch.sum(y1/y2 + y2/y1) / y1.numel()\n",
        "\n",
        "def logarithmic_loss(y1, y2):\n",
        "    return l1(torch.log(y1), torch.log(y2)) * 10\n",
        "\n",
        "def distance_loss(y1, y2):\n",
        "    return l1(distance_matrix(y1), distance_matrix(y2)) / 100\n",
        "\n",
        "def distance_temp_loss(y1, y2):\n",
        "    return l1(distance_temp_matrix(y1), distance_temp_matrix(y2)) / 100\n",
        "\n",
        "def distance_matrix(y):\n",
        "    #y B*T*PCA => (B*T)*PCA =>dist (B*T)*(B*T)\n",
        "    mat_y = y.reshape(-1, y.shape[-1])\n",
        "    pairwise = torch.mm(mat_y, mat_y.transpose(0,1))\n",
        "    lens = torch.diag(pairwise)\n",
        "    return pairwise - lens[:, None] - lens[None, :]\n",
        "\n",
        "def distance_temp_matrix(y):\n",
        "    pairwise = torch.bmm(y, y.transpose(2,1))\n",
        "    lens = torch.diagonal(pairwise, dim1=1, dim2=2)\n",
        "    return pairwise - lens[:, :, None] - lens[:, None, :]\n",
        "\n",
        "def delay_loss(preds, y, loss, delay):\n",
        "    y_pred = preds[:, delay:, :] #remove_delay\n",
        "    return l1(y_pred, y)\n",
        "    # distance_temp_loss(y_pred, y)\n",
        "    # distance_loss(y_pred, y) \n",
        "    # hyperbolic_loss(inner_lip_distance(y_pred), inner_lip_distance(y)) * 10 \n",
        "    # loss(y_pred, y)\n",
        "\n",
        "#standard loss function\n",
        "def delay_std_loss(preds, y, loss, delay):\n",
        "    y_pred = preds[:, delay:, :]\n",
        "    return loss(y_pred, y)\n",
        "\n",
        "\n",
        "l1 = nn.L1Loss()\n",
        "loss = nn.MSELoss()"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_QhXuio8HhRA",
        "outputId": "ea50cfa5-e1a1-437c-aa9e-710ec8ff1947"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    optimizer = optim.SGD(model.parameters(), lr=1, momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
        "    n_epochs = 300\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, gamma=0.5, milestones=np.array([0.2,0.4,0.6,0.8]) * n_epochs)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_st_losses = []\n",
        "    for epoch in tqdm(range(n_epochs)):            \n",
        "        model.train()\n",
        "        l_tot = 0\n",
        "        num_batch = 0\n",
        "        for X, y, _ in train_dataloader:\n",
        "            X, y = X.cuda(), y.cuda()\n",
        "            preds = model(X.double())\n",
        "            l = delay_loss(preds, y, loss, video_shft)\n",
        "            #print('training loss:', l)\n",
        "            l_tot += l.item()\n",
        "            l.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            num_batch += 1\n",
        "        scheduler.step()\n",
        "        train_losses.append(l_tot/num_batch)   \n",
        "        \n",
        "        if epoch % (n_epochs//20) == 0:   \n",
        "            model.eval()         \n",
        "            l_val_tot = 0\n",
        "            l_val_st_tot = 0\n",
        "            num_val_batch = 0\n",
        "            for X_val, y_val, _ in test_dataloader:\n",
        "                X_val, y_val = X_val.cuda(), y_val.cuda()\n",
        "                preds_val = model(X_val.double())\n",
        "\n",
        "                l_val = delay_loss(preds_val, y_val, loss, video_shft)\n",
        "                l_val_st = delay_std_loss(preds_val, y_val, loss, video_shft)\n",
        "                l_val_tot += l_val.item()\n",
        "                l_val_st_tot += l_val_st.item()\n",
        "                num_val_batch += 1\n",
        "\n",
        "            val_losses.append(l_val_tot/num_val_batch) \n",
        "            val_st_losses.append(l_val_st_tot/num_val_batch)   \n",
        "            #scheduler.step(l_val_tot/num_val_batch)\n",
        "\n",
        "            print('epoch: ', epoch)\n",
        "            print('training loss:', l_tot/num_batch)   \n",
        "            print('validation loss:', l_val_tot/num_val_batch)\n",
        "            print('validation loss std:', l_val_st_tot/num_val_batch)\n",
        " \n",
        "finally:\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(train_losses)\n",
        "    ax.plot(list(range(0, len(val_losses) * (n_epochs//20), (n_epochs//20))), val_losses)\n",
        "    plt.savefig(f'losses_{n_epochs}_l1.png')            \n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    #ax.plot(list(range(0, len(val_losses) * (n_epochs//20), (n_epochs//20))), val_st_losses)\n",
        "    #plt.savefig(f'losses_st_{n_epochs}_disttemp.png')"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/300 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "  0%|          | 1/300 [00:00<00:34,  8.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "  1%|          | 2/300 [00:00<00:34,  8.66it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  0\n",
            "training loss: 1.0958932494033062\n",
            "validation loss: 1.0991150653531814\n",
            "validation loss std: 7.863989137882231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  1%|          | 3/300 [00:00<00:33,  8.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 5/300 [00:00<00:31,  9.24it/s]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 6/300 [00:00<00:31,  9.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 8/300 [00:00<00:30,  9.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 9/300 [00:00<00:30,  9.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▎         | 11/300 [00:01<00:28,  9.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▍         | 13/300 [00:01<00:28, 10.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▍         | 14/300 [00:01<00:28,  9.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▌         | 16/300 [00:01<00:28,  9.97it/s]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▌         | 17/300 [00:01<00:28,  9.92it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  15\n",
            "training loss: 0.9693944365152064\n",
            "validation loss: 1.0752600567802812\n",
            "validation loss std: 7.624638835275134\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  6%|▌         | 18/300 [00:01<00:28,  9.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▋         | 19/300 [00:01<00:28,  9.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 20/300 [00:02<00:28,  9.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 21/300 [00:02<00:28,  9.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 22/300 [00:02<00:28,  9.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 23/300 [00:02<00:29,  9.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 25/300 [00:02<00:27,  9.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▉         | 27/300 [00:02<00:27, 10.08it/s]\u001b[A\u001b[A\n",
            "\n",
            " 10%|▉         | 29/300 [00:02<00:26, 10.18it/s]\u001b[A\u001b[A\n",
            "\n",
            " 10%|█         | 31/300 [00:03<00:27,  9.93it/s]\u001b[A\u001b[A\n",
            "\n",
            " 11%|█         | 32/300 [00:03<00:27,  9.90it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  30\n",
            "training loss: 0.967854526954197\n",
            "validation loss: 1.075345503422136\n",
            "validation loss std: 7.636947775563257\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 11%|█▏        | 34/300 [00:03<00:26, 10.09it/s]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 36/300 [00:03<00:26, 10.06it/s]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 38/300 [00:03<00:25, 10.23it/s]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 40/300 [00:03<00:24, 10.40it/s]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▍        | 42/300 [00:04<00:24, 10.34it/s]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▍        | 44/300 [00:04<00:24, 10.30it/s]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▌        | 46/300 [00:04<00:25, 10.10it/s]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▌        | 48/300 [00:04<00:24, 10.14it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  45\n",
            "training loss: 0.9670706835863347\n",
            "validation loss: 1.0753557469133797\n",
            "validation loss std: 7.63575417444076\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 17%|█▋        | 50/300 [00:04<00:24, 10.31it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 52/300 [00:05<00:23, 10.41it/s]\u001b[A\u001b[A\n",
            "\n",
            " 18%|█▊        | 54/300 [00:05<00:23, 10.30it/s]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▊        | 56/300 [00:05<00:23, 10.28it/s]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▉        | 58/300 [00:05<00:23, 10.45it/s]\u001b[A\u001b[A\n",
            "\n",
            " 20%|██        | 60/300 [00:05<00:22, 10.53it/s]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 62/300 [00:06<00:22, 10.40it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  60\n",
            "training loss: 0.965815773552329\n",
            "validation loss: 1.0744662986040183\n",
            "validation loss std: 7.626912251572785\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 21%|██▏       | 64/300 [00:06<00:22, 10.41it/s]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 66/300 [00:06<00:22, 10.27it/s]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 68/300 [00:06<00:22, 10.23it/s]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 70/300 [00:06<00:22, 10.21it/s]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▍       | 72/300 [00:07<00:22, 10.28it/s]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▍       | 74/300 [00:07<00:21, 10.31it/s]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▌       | 76/300 [00:07<00:22, 10.09it/s]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 78/300 [00:07<00:21, 10.20it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  75\n",
            "training loss: 0.9655304615409743\n",
            "validation loss: 1.075401060623124\n",
            "validation loss std: 7.648638211331875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 27%|██▋       | 80/300 [00:07<00:21, 10.23it/s]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 82/300 [00:08<00:21, 10.24it/s]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 84/300 [00:08<00:21, 10.28it/s]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▊       | 86/300 [00:08<00:20, 10.31it/s]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 88/300 [00:08<00:20, 10.46it/s]\u001b[A\u001b[A\n",
            "\n",
            " 30%|███       | 90/300 [00:08<00:20, 10.44it/s]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███       | 92/300 [00:09<00:20, 10.17it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  90\n",
            "training loss: 0.9651730190918528\n",
            "validation loss: 1.0755775317096803\n",
            "validation loss std: 7.656352521748212\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 31%|███▏      | 94/300 [00:09<00:20, 10.22it/s]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 96/300 [00:09<00:19, 10.30it/s]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 98/300 [00:09<00:19, 10.40it/s]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 100/300 [00:09<00:18, 10.53it/s]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 102/300 [00:09<00:18, 10.52it/s]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▍      | 104/300 [00:10<00:18, 10.39it/s]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▌      | 106/300 [00:10<00:19, 10.12it/s]\u001b[A\u001b[A\n",
            "\n",
            " 36%|███▌      | 108/300 [00:10<00:18, 10.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  105\n",
            "training loss: 0.9647440595422125\n",
            "validation loss: 1.0758635455075536\n",
            "validation loss std: 7.666718662978427\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 110/300 [00:10<00:18, 10.19it/s]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 112/300 [00:10<00:18, 10.33it/s]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 114/300 [00:11<00:17, 10.36it/s]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▊      | 116/300 [00:11<00:17, 10.28it/s]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▉      | 118/300 [00:11<00:17, 10.30it/s]\u001b[A\u001b[A\n",
            "\n",
            " 40%|████      | 120/300 [00:11<00:17, 10.45it/s]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████      | 122/300 [00:11<00:17, 10.10it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  120\n",
            "training loss: 0.9642527963409228\n",
            "validation loss: 1.0750119344795104\n",
            "validation loss std: 7.651954245753006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 41%|████▏     | 124/300 [00:12<00:17, 10.27it/s]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 126/300 [00:12<00:16, 10.30it/s]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 128/300 [00:12<00:16, 10.25it/s]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 130/300 [00:12<00:16, 10.21it/s]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▍     | 132/300 [00:12<00:16, 10.21it/s]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▍     | 134/300 [00:13<00:16, 10.23it/s]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▌     | 136/300 [00:13<00:16, 10.19it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  135\n",
            "training loss: 0.9644482843535804\n",
            "validation loss: 1.0750186549499885\n",
            "validation loss std: 7.644416502978979\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 46%|████▌     | 138/300 [00:13<00:16, 10.03it/s]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 140/300 [00:13<00:15, 10.12it/s]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 142/300 [00:13<00:15, 10.16it/s]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 144/300 [00:14<00:15, 10.25it/s]\u001b[A\u001b[A\n",
            "\n",
            " 49%|████▊     | 146/300 [00:14<00:14, 10.30it/s]\u001b[A\u001b[A\n",
            "\n",
            " 49%|████▉     | 148/300 [00:14<00:14, 10.40it/s]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 150/300 [00:14<00:14, 10.38it/s]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████     | 152/300 [00:14<00:14, 10.04it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  150\n",
            "training loss: 0.96368640916279\n",
            "validation loss: 1.0754391362805313\n",
            "validation loss std: 7.655713974883468\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 51%|█████▏    | 154/300 [00:15<00:14,  9.97it/s]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 155/300 [00:15<00:14,  9.83it/s]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 156/300 [00:15<00:14,  9.86it/s]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 158/300 [00:15<00:14, 10.11it/s]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 160/300 [00:15<00:13, 10.22it/s]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▍    | 162/300 [00:15<00:13, 10.24it/s]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▍    | 164/300 [00:16<00:13, 10.18it/s]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▌    | 166/300 [00:16<00:13, 10.17it/s]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 168/300 [00:16<00:13, 10.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  165\n",
            "training loss: 0.9643572204317106\n",
            "validation loss: 1.0754496913810307\n",
            "validation loss std: 7.661829658135888\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 170/300 [00:16<00:12, 10.28it/s]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 172/300 [00:16<00:12, 10.36it/s]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 174/300 [00:17<00:12, 10.32it/s]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▊    | 176/300 [00:17<00:12, 10.31it/s]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▉    | 178/300 [00:17<00:11, 10.26it/s]\u001b[A\u001b[A\n",
            "\n",
            " 60%|██████    | 180/300 [00:17<00:11, 10.23it/s]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████    | 182/300 [00:17<00:11, 10.12it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  180\n",
            "training loss: 0.9637372725842559\n",
            "validation loss: 1.0753801870592101\n",
            "validation loss std: 7.652429527611528\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 61%|██████▏   | 184/300 [00:18<00:11, 10.19it/s]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 186/300 [00:18<00:11, 10.17it/s]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 188/300 [00:18<00:11, 10.18it/s]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 190/300 [00:18<00:10, 10.33it/s]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▍   | 192/300 [00:18<00:10, 10.33it/s]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▍   | 194/300 [00:18<00:10, 10.41it/s]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▌   | 196/300 [00:19<00:10, 10.20it/s]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▌   | 198/300 [00:19<00:10, 10.19it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  195\n",
            "training loss: 0.9637362651332468\n",
            "validation loss: 1.0755162617638787\n",
            "validation loss std: 7.652276782360216\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 67%|██████▋   | 200/300 [00:19<00:10,  9.96it/s]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 201/300 [00:19<00:09,  9.90it/s]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 202/300 [00:19<00:09,  9.87it/s]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 203/300 [00:19<00:09,  9.80it/s]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 204/300 [00:20<00:09,  9.85it/s]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▊   | 206/300 [00:20<00:09, 10.09it/s]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▉   | 208/300 [00:20<00:09, 10.18it/s]\u001b[A\u001b[A\n",
            "\n",
            " 70%|███████   | 210/300 [00:20<00:08, 10.21it/s]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████   | 212/300 [00:20<00:08, 10.04it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  210\n",
            "training loss: 0.9634844328871589\n",
            "validation loss: 1.076299369620803\n",
            "validation loss std: 7.657569439432197\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 71%|███████▏  | 214/300 [00:20<00:08, 10.09it/s]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 216/300 [00:21<00:08, 10.10it/s]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 218/300 [00:21<00:07, 10.27it/s]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 220/300 [00:21<00:07, 10.21it/s]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▍  | 222/300 [00:21<00:07, 10.05it/s]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▍  | 224/300 [00:21<00:07, 10.11it/s]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▌  | 226/300 [00:22<00:07,  9.90it/s]\u001b[A\u001b[A\n",
            "\n",
            " 76%|███████▌  | 228/300 [00:22<00:07, 10.05it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  225\n",
            "training loss: 0.9636342997207167\n",
            "validation loss: 1.0758887960134154\n",
            "validation loss std: 7.662340114196729\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 77%|███████▋  | 230/300 [00:22<00:06, 10.18it/s]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 232/300 [00:22<00:06, 10.12it/s]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 234/300 [00:22<00:06, 10.09it/s]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▊  | 236/300 [00:23<00:06, 10.19it/s]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 238/300 [00:23<00:06, 10.31it/s]\u001b[A\u001b[A\n",
            "\n",
            " 80%|████████  | 240/300 [00:23<00:05, 10.24it/s]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████  | 242/300 [00:23<00:05, 10.03it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  240\n",
            "training loss: 0.9631993424371218\n",
            "validation loss: 1.076370944015453\n",
            "validation loss std: 7.671203494957747\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 81%|████████▏ | 244/300 [00:23<00:05, 10.09it/s]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 246/300 [00:24<00:05, 10.04it/s]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 248/300 [00:24<00:05, 10.02it/s]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 250/300 [00:24<00:04, 10.03it/s]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▍ | 252/300 [00:24<00:04, 10.14it/s]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▍ | 254/300 [00:24<00:04, 10.30it/s]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▌ | 256/300 [00:25<00:04, 10.04it/s]\u001b[A\u001b[A\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  255\n",
            "training loss: 0.9633840256320105\n",
            "validation loss: 1.0757848851271719\n",
            "validation loss std: 7.6576239307407095\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 86%|████████▌ | 258/300 [00:25<00:04, 10.05it/s]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 260/300 [00:25<00:03, 10.20it/s]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 262/300 [00:25<00:03, 10.21it/s]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 264/300 [00:25<00:03, 10.28it/s]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▊ | 266/300 [00:26<00:03, 10.39it/s]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▉ | 268/300 [00:26<00:03, 10.30it/s]\u001b[A\u001b[A\n",
            "\n",
            " 90%|█████████ | 270/300 [00:26<00:02, 10.24it/s]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████ | 272/300 [00:26<00:02,  9.85it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  270\n",
            "training loss: 0.963287758991984\n",
            "validation loss: 1.0765063143946698\n",
            "validation loss std: 7.664597180566709\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 91%|█████████ | 273/300 [00:26<00:02,  9.67it/s]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 275/300 [00:27<00:02,  9.92it/s]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 277/300 [00:27<00:02, 10.16it/s]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 279/300 [00:27<00:02, 10.12it/s]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▎| 281/300 [00:27<00:01, 10.14it/s]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▍| 283/300 [00:27<00:01, 10.18it/s]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▌| 285/300 [00:27<00:01, 10.27it/s]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▌| 287/300 [00:28<00:01, 10.13it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  285\n",
            "training loss: 0.9635183695505102\n",
            "validation loss: 1.0762445746082274\n",
            "validation loss std: 7.668648579516592\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 96%|█████████▋| 289/300 [00:28<00:01, 10.22it/s]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 291/300 [00:28<00:00, 10.27it/s]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 293/300 [00:28<00:00, 10.16it/s]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 295/300 [00:28<00:00, 10.14it/s]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▉| 297/300 [00:29<00:00, 10.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 300/300 [00:29<00:00, 10.18it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt2Mj_DWI_-k"
      },
      "source": [
        "model.eval()\n",
        "#all_data = FacePredictDataset(audio_data, lips_upsampled, video_shft, video_start, 1)\n",
        "#test_dataloader = DataLoader(all_data, batch_size = 1)\n",
        "#test_dataloader = DataLoader(test_data, batch_size=300, shuffle=True)\n",
        "X_val, y_val, val_starts = test_dataloader.__iter__().next()\n",
        "X_val, y_val = X_val.cuda(), y_val.cuda()\n",
        "preds_val = model(X_val.double())\n",
        "sample_pred = preds_val.detach().cpu().numpy()[:, video_shft:].reshape(-1, 20)\n",
        "sample_lips = pca.inverse_transform(sample_pred)\n",
        "true_lips = pca.inverse_transform(y_val.cpu().reshape(-1, 20))\n",
        "print((val_starts + idx_split)*30/100 + 12)\n",
        "print(sample_pred.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCG3aDPZd2kM"
      },
      "source": [
        "#downsample predictions to 30 fps\n",
        "preds_timess = [np.arange(video_start + val_st, video_start + val_st + test_data.crop_len) / 100 for val_st in val_starts + idx_split]\n",
        "downsample_timess = [np.arange(int(min(preds_t) * 30) + 1, int(max(preds_t) * 30)) / 30 for preds_t in preds_timess]\n",
        "preds_times = np.concatenate(preds_timess)\n",
        "downsample_times = np.sort(np.concatenate(downsample_timess))\n",
        "\n",
        "print(preds_times.shape, sample_lips.shape)\n",
        "preds_interpolate = interp1d(preds_times, sample_lips, axis = 0)\n",
        "downsample_preds = preds_interpolate(downsample_times)\n",
        "\n",
        "true_interpolate = interp1d(preds_times, true_lips, axis = 0)\n",
        "downsample_true = true_interpolate(downsample_times)\n",
        "\n",
        "print(min(downsample_times)*30, max(downsample_times)*30)\n",
        "print(downsample_preds.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlNeCSSdO9MM"
      },
      "source": [
        "np.save('/content/drive/MyDrive/6869/sample_lips', sample_lips)\n",
        "np.save('/content/drive/MyDrive/6869/downsample_preds', downsample_preds)\n",
        "np.save('/content/drive/MyDrive/6869/downsample_true', downsample_true)\n",
        "np.save('/content/drive/MyDrive/6869/downsample_times', downsample_times)\n",
        "\n",
        "import pandas as pd\n",
        "pd.DataFrame(sample_lips).to_csv('/content/drive/MyDrive/6869/sample_lips.csv', sep=' ', index=False, header=False)\n",
        "pd.DataFrame(downsample_preds).to_csv('/content/drive/MyDrive/6869/downsample_preds.csv', sep=' ', index=False, header=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq4bhr73FOHT"
      },
      "source": [
        "#!cp /content/losses_300_dist.png /content/drive/MyDrive/6869/\n",
        "#!cp /content/losses_300_hyp.png /content/drive/MyDrive/6869/\n",
        "#!cp /content/losses_300_l2.png /content/drive/MyDrive/6869/\n",
        "#!cp /content/losses_300_disttemp.png /content/drive/MyDrive/6869/\n",
        "!cp /content/losses_300_l1.png /content/drive/MyDrive/6869/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJO3AGo48OLQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qfS34dYMcXt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}